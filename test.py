import os
import numpy as np
import mlflow
import mlflow.keras
from mlflow.models.signature import infer_signature
from tensorflow.keras.models import load_model
import shutil

# =========================
# Config
# =========================
MODEL_PATH = "best_model.keras"
EXPERIMENT_NAME = "xception_fake_real"
ARTIFACT_DIR = "final_model"

# DagsHub credentials
DAGSHUB_USERNAME = "Slothdemon22"
DAGSHUB_TOKEN = "a50bc6e3b74b10f5c959b12bce5de638474e7b48"
REPO_NAME = "mlops-project"

# =========================
# MLflow Tracking Setup
# =========================
os.environ["MLFLOW_TRACKING_URI"] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{REPO_NAME}.mlflow"
os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

mlflow.set_experiment(EXPERIMENT_NAME)

# =========================
# Load model
# =========================
print("Loading model...")
keras_model = load_model(MODEL_PATH)
print(f"âœ… Model loaded from {MODEL_PATH}")

# =========================
# Infer signature from dummy input
# =========================
dummy_input = np.random.rand(1, 256, 256, 3).astype(np.float32) * 255
predictions = keras_model.predict(dummy_input, verbose=0)
signature = infer_signature(dummy_input, predictions)

# =========================
# Start MLflow run and log everything
# =========================
with mlflow.start_run() as run:
    run_id = run.info.run_id
    print(f"âœ… Started MLflow run with ID: {run_id}")

    # Log parameters
    params = {
        "img_size": "(256,256)",
        "batch_size": 32,
        "epochs": 20,
        "dropout": 0.3,
        "optimizer": "Adam",
        "learning_rate_phase1": 1e-4,
        "learning_rate_phase2": 1e-5,
        "label_smoothing": 0.1,
        "fine_tune_last_layers": 50
    }
    mlflow.log_params(params)
    print("âœ… Parameters logged")

    # Log metrics
    metrics = {
        "val_accuracy": 0.95,
        "val_loss": 0.2,
        "train_accuracy": 0.97,
        "train_loss": 0.15
    }
    mlflow.log_metrics(metrics)
    print("âœ… Metrics logged")

    # =========================
    # Log Keras model (with fallback)
    # =========================
    try:
        mlflow.keras.log_model(
            keras_model,
            artifact_path=ARTIFACT_DIR,
            signature=signature
        )
        print(f"âœ… Model logged directly to MLflow as '{ARTIFACT_DIR}'")
    except Exception as e:
        print("âš ï¸ Direct log_model failed, using fallback method:", e)
        temp_dir = f"temp_{ARTIFACT_DIR}"
        mlflow.keras.save_model(
            keras_model,
            path=temp_dir,
            signature=signature
        )
        mlflow.log_artifacts(temp_dir, artifact_path=ARTIFACT_DIR)
        shutil.rmtree(temp_dir)
        print(f"âœ… Model logged using fallback to '{ARTIFACT_DIR}'")

    # Also log original model file
    mlflow.log_artifact(MODEL_PATH, artifact_path="original_model")
    print("âœ… Original model file logged")

print("\n" + "="*70)
print(f"ðŸŽ‰ SUCCESS! Model logged successfully!")
print(f"ðŸ“Š Run URL: https://dagshub.com/{DAGSHUB_USERNAME}/{REPO_NAME}.mlflow/#/experiments/3/runs/{run_id}")
print("="*70 + "\n")

# =========================
# Load and test the model
# =========================
print("Testing model loading...")
model_uri = f"runs:/{run_id}/{ARTIFACT_DIR}"
loaded_model = mlflow.keras.load_model(model_uri)
print("âœ… Model loaded successfully from MLflow")

# Test prediction
test_input = np.random.rand(1, 256, 256, 3).astype(np.float32) * 255
pred = loaded_model.predict(test_input, verbose=0)
print(f"\nðŸ“ˆ Test Prediction Results:")
print(f"   Input shape: {test_input.shape}")
print(f"   Prediction shape: {pred.shape}")
print(f"   Prediction values: {pred}")
print(f"   Predicted class: {'REAL' if pred[0][0] > 0.5 else 'FAKE'} (confidence: {pred[0][0]:.4f})")

print("\nâœ… All tests passed!")
